{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re\n",
    "mystem = Mystem()\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Александра\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Александра\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "pd.set_option('max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/sentiment_twitter/train_sentiment_ttk.tsv', sep='\\t')\n",
    "test_data = pd.read_csv('data/sentiment_twitter/test_sentiment_ttk.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@mkomov Максим, Вашем письмо мы получили. Наши сотрудники свяжутся с Вами завтра и направят запрос инженерам для проверки. #билайн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>«Мегафон» стал владельцем 50% акций «Евросети»</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>RT @fuckkiev: “@EvaKobb: МТС Россия прислала жителям Херсонщины сообщения, в которых обозвала украинцев фашистами? http://t.co/RbSesXlOUZ” …</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ВИДЕО: http://t.co/PSMLAhR4fI Реклама со смехом МТС - Супер 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>@parfenov1960 потому что МТС достало, а пчел ненавижу с детства, как и их мёд!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2     -1   \n",
       "3      1   \n",
       "4     -1   \n",
       "\n",
       "                                                                                                                                           text  \n",
       "0            @mkomov Максим, Вашем письмо мы получили. Наши сотрудники свяжутся с Вами завтра и направят запрос инженерам для проверки. #билайн  \n",
       "1                                                                                                «Мегафон» стал владельцем 50% акций «Евросети»  \n",
       "2  RT @fuckkiev: “@EvaKobb: МТС Россия прислала жителям Херсонщины сообщения, в которых обозвала украинцев фашистами? http://t.co/RbSesXlOUZ” …  \n",
       "3                                                                                 ВИДЕО: http://t.co/PSMLAhR4fI Реклама со смехом МТС - Супер 0  \n",
       "4                                                                @parfenov1960 потому что МТС достало, а пчел ненавижу с детства, как и их мёд!  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>RT vzglyad: По делу о работе МТС в Узбекистане США предложили заморозить 300 млн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @kevinuyatukox: http://t.co/ljtrjq91v3 #Кредитные карты мегафон банка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>#Оформить кредитную карту в банке мтс http://t.co/vv1B6PMWgH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#Как перевести деньги с билайна на кредитную карту</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#Начальник отдела кредитного контроля оао мтс усачева н а</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0     -1   \n",
       "1      0   \n",
       "2      0   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                               text  \n",
       "0  RT vzglyad: По делу о работе МТС в Узбекистане США предложили заморозить 300 млн  \n",
       "1          RT @kevinuyatukox: http://t.co/ljtrjq91v3 #Кредитные карты мегафон банка  \n",
       "2                      #Оформить кредитную карту в банке мтс http://t.co/vv1B6PMWgH  \n",
       "3                                #Как перевести деньги с билайна на кредитную карту  \n",
       "4                         #Начальник отдела кредитного контроля оао мтс усачева н а  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.0\n",
    "Бейзлайн без нормализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vecrotizer(train_data, test_data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    count_vectorizer.fit(train_data.values) \n",
    "\n",
    "    X_train = count_vectorizer.transform(train_data.values)\n",
    "    X_test = count_vectorizer.transform(test_data.values)\n",
    "    return X_train, X_test, count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, count_vectorizer = Vecrotizer(train_data.text, test_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8208, 20511)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2054, 20511)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data.label.values\n",
    "y_test = test_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridS(X_train, y_train):\n",
    "    log = LogisticRegression(penalty=\"l1\")\n",
    "    params = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    clf = GridSearchCV(log, param_grid=params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gridS(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X_train_2, y_train, X_test_2, y_test):\n",
    "    clf = LogisticRegression(penalty=\"l1\", C=10)\n",
    "    clf.fit(X_train_2, y_train)\n",
    "    y_pred_2 = clf.predict(X_test_2)\n",
    "    normal = accuracy_score(y_test, y_pred_2)\n",
    "    return clf, normal, y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, base_line, y_pred = logistic(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6718597857838364"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.73      0.66      0.70       902\n",
      "          0       0.66      0.76      0.71       972\n",
      "          1       0.35      0.26      0.30       180\n",
      "\n",
      "avg / total       0.67      0.67      0.67      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.568121798443427\n",
      "Микросредняя F1 мера -  0.6718597857838364\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('Макросредняя F1 мера - ',f1_score(y_test, y_pred, average='macro'))\n",
    "print('Микросредняя F1 мера - ',f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significant(vectorizer, clf, top=10):\n",
    "    words = vectorizer.get_feature_names()\n",
    "    classes = clf.classes_\n",
    "    imp = clf.coef_\n",
    "    for el, cls in enumerate(classes):\n",
    "        sign_words = sorted(list(zip(words, imp[el])), key=lambda x: abs(x[1]), reverse=True)[:top]\n",
    "        print('Class ' + str(cls) + ': \\n',\n",
    "              [word for word,_ in sign_words], '\\n\\n'\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class -1: \n",
      " ['собираются', 'сбой', 'evakobb', 'обман', 'отправлялись', 'нему', 'керчи', 'перебоями', 'amaranth815', 'прогресс'] \n",
      "\n",
      "\n",
      "Class 0: \n",
      " ['нему', 'собираются', 'хороший', 'жителям', 'прокомментировала', 'jivh4eenpq', 'расторгнуть', 'иа', 'прочность', 'гавно'] \n",
      "\n",
      "\n",
      "Class 1: \n",
      " ['здорово', 'фотоед', 'специалистом', 'ожидал', 'радовать', 'обожаю', 't1cw25qbrz', 'расширяется', 'люблю', 'выросла'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "significant(count_vectorizer, clf, top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить результат с помощью лемматицации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.1\n",
    "Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation, digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готовый набор стоп-слов для русского языка возьмём из nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['и', 'в', 'во', 'не', 'что', 'он']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('russian')\n",
    "stop_words[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation + '«»—…“”\\n\\t' + digits)\n",
    "punctuation.remove('@')\n",
    "table = str.maketrans({ch: None for ch in punctuation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \n",
    "    clean_data = []\n",
    "    \n",
    "    good_words = [\n",
    "        word for word in word_tokenize(text) if len(text) > 1 and not all([ch in punctuation for ch in word])]\n",
    "    \n",
    "    words_normalized = [morph.parse(token)[0].normal_form for token in good_words]\n",
    "    \n",
    "    for word in words_normalized:\n",
    "        if word not in stop_words:\n",
    "            clean_data.append(word)\n",
    "\n",
    "    return ' '.join(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['normalized'] = train_data['text'].apply(normalize)\n",
    "test_data['normalized'] = test_data['text'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, count_vectorizer = Vecrotizer(train_data.normalized, test_data.normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8208, 14436)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2054, 14436)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, normalized, y_pred_2 = logistic(X_train_2, y_train, X_test_2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6640701071080818"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.75      0.62      0.67       902\n",
      "          0       0.66      0.77      0.71       972\n",
      "          1       0.35      0.32      0.34       180\n",
      "\n",
      "avg / total       0.67      0.66      0.66      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.5733628472525057\n",
      "Микросредняя F1 мера -  0.6640701071080818\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_2))\n",
    "print('Макросредняя F1 мера - ',f1_score(y_test, y_pred_2, average='macro'))\n",
    "print('Микросредняя F1 мера - ',f1_score(y_test, y_pred_2, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат немного ухудшился. Скорее всего, это связано с тем, что в рамках твита (длина которого ограничена 140 символами), некоторые стоп-слова имеют в реальности большое значение. Попробуем улучшить результат как-то по-другому"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задания 2.0-2.2\n",
    "Проанализировать важные признаки, fp, fn, confusion matrix, изменить правила препроцессинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала, попробуем не убирать стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_stops(text):\n",
    "    \n",
    "    \n",
    "    good_words = [\n",
    "        word for word in word_tokenize(text) if len(text) > 1 and not all([ch in punctuation for ch in word])]\n",
    "    \n",
    "    words_normalized = [morph.parse(token)[0].normal_form for token in good_words]\n",
    "    \n",
    "    return ' '.join(words_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['normalized_with_stops'] = train_data['text'].apply(normalize_stops)\n",
    "test_data['normalized_with_stops'] = test_data['text'].apply(normalize_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, X_test_3, count_vectorizer = Vecrotizer(train_data.normalized_with_stops, test_data.normalized_with_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, normalized_with_stops, y_pred_3 = logistic(X_train_3, y_train, X_test_3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6786757546251218"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_with_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.73      0.67      0.70       902\n",
      "          0       0.67      0.76      0.71       972\n",
      "          1       0.42      0.33      0.37       180\n",
      "\n",
      "avg / total       0.68      0.68      0.68      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.5935328585793745\n",
      "Микросредняя F1 мера -  0.6786757546251218\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_3))\n",
    "print('Макросредняя F1 мера - ',f1_score(y_test, y_pred_3, average='macro'))\n",
    "print('Микросредняя F1 мера - ',f1_score(y_test, y_pred_3, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class -1: \n",
      " ['задолженность', 'amaranth815', 'оштрафовать', 'атаковать', 'сбой', 'турбокнопка', 'уезжать', 'добиться', 'расторгнуть', 'испытывать'] \n",
      "\n",
      "\n",
      "Class 0: \n",
      " ['650р', 'топливо', 'расторгнуть', 'гавный', 'испытывать', 'вносить', 'достоверно', 'слогана', 'инноватор', 'поведенческий'] \n",
      "\n",
      "\n",
      "Class 1: \n",
      " ['lizinastusha', 'здорово', 'адекватный', '6j3mfzcy5u', 'мило', 'топливо', 'расширяться', 'инноватор', 'youdicuudv', 'защита'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "significant(count_vectorizer, clf, top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что получилось:\n",
    "- некоторые слова относятся к нескольким классам (\"топливо\", \"инноватор\", \"испытывать\", \"расторгнуть\"), что усложняет их разделение\n",
    "- класс с положительными твитами может отделяется значительно хуже остальных. Думаю, это связано с тем, что идентефицировать негативно окрашенные слова проще, чем положительно. \n",
    "\n",
    "Проверим последний пункт по Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[600, 272,  30],\n",
       "       [186, 734,  52],\n",
       "       [ 37,  83,  60]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действительно, наша программа плохо разграничивает классы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.3-2.4\n",
    "Подобрать параметры в классификаторе и векторайзере и произвести отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала сравним те модели, которые у нас уже есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TfidfVectorize(train_data, test_data):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf.fit(train_data.values)\n",
    "    X_train = tfidf.transform(train_data.values)\n",
    "    X_test = tfidf.transform(test_data.values)\n",
    "    return X_train, X_test, tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, tfidf = TfidfVectorize(train_data.text, test_data.text)\n",
    "clf, base_line_tf, y_pred = logistic(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, tfidf_2 = TfidfVectorize(train_data.normalized, test_data.normalized)\n",
    "clf, normalized_stop_tf, y_pred_2 = logistic(X_train_2, y_train, X_test_2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, X_test_3, tfidf_3 = TfidfVectorize(train_data.normalized_with_stops, test_data.normalized_with_stops)\n",
    "clf, normalized_no_stops_tf, y_pred_3 = logistic(X_train_3, y_train, X_test_3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6650438169425511"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_line_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6504381694255112"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_stop_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6713729308666018"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_no_stops_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class -1: \n",
      " ['кобо', 'нахрен', 'sashaselfish', 'zi24akrlsw', 'быстрые', 'adoralim', 'маршрутизатора', 'инет', 'отдых', 'грамотности'] \n",
      "\n",
      "\n",
      "Class 0: \n",
      " ['бреста', 'оповещениями', 'гейнеры', 'биатлону', 'набрехали', '3гб', 'краже', 'внятно', 'перебежчиках', 'голос'] \n",
      "\n",
      "\n",
      "Class 1: \n",
      " ['kalars07', 'y6atjvkiud', 'вышки', 'лицензионным', 'загрузились', 'выставка', 'голос', '424', 'перезвонит', 'влияет'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "significant(tfidf, clf, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class -1: \n",
      " ['памятник', 'светлый', 'tele2', 'атаковать', 'говорить', 'beeline_omsk', 'прибытие', 'ободрать', 'україный', 'исходящи'] \n",
      "\n",
      "\n",
      "Class 0: \n",
      " ['газ', 'транзит', 'игра', 'восточный', 'реагировать', '650р', 'повторяться', 'домен', 'ция', 'инстаграмм'] \n",
      "\n",
      "\n",
      "Class 1: \n",
      " ['lizinastusha', 'адекватный', 'зеленодольск', 'попробовать', 'мтс970', 'збс', 'инстаграмм', '6j3mfzcy5u', 'честнаялига', 'договариваться'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "significant(tfidf_2, clf, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class -1: \n",
      " ['оштрафовать', 'сбой', 'tele2', 'атаковать', 'говно', 'beeline_omsk', 'прекрасно', 'обман', 'уезжать', 'испытывать'] \n",
      "\n",
      "\n",
      "Class 0: \n",
      " ['гавный', 'топливо', 'иа', 'восстановление', 'расторгнуть', '650р', 'поведенческий', 'доллар', 'хуй', 'инноватор'] \n",
      "\n",
      "\n",
      "Class 1: \n",
      " ['lizinastusha', 'адекватный', 'здорово', 'понравиться', 'мощь', 'защита', 'инноватор', '6j3mfzcy5u', 'частный', 'довольный'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "significant(tfidf_3, clf, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountVec</th>\n",
       "      <th>TfidfVec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>StarterPack</th>\n",
       "      <td>0.671860</td>\n",
       "      <td>0.665044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalized_no_Stops</th>\n",
       "      <td>0.664070</td>\n",
       "      <td>0.650438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalized_with_Stops</th>\n",
       "      <td>0.678676</td>\n",
       "      <td>0.671373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       CountVec  TfidfVec\n",
       "StarterPack            0.671860  0.665044\n",
       "Normalized_no_Stops    0.664070  0.650438\n",
       "Normalized_with_Stops  0.678676  0.671373"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'CountVec': [base_line, normalized, normalized_with_stops],\n",
    "              'TfidfVec': [base_line_tf, normalized_stop_tf, normalized_no_stops_tf]\n",
    "             }, index=['StarterPack', 'Normalized_no_Stops', 'Normalized_with_Stops'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C tf-idf стало хуже, постараемся улучшить CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к отбору признаков:\n",
    "- создадим свой список стоп-слов, т.е. слов, которые присутсвуют во всех классах, а значит, не играют большой роли при классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common(vectorizer, clf, top=10):\n",
    "    words = vectorizer.get_feature_names()\n",
    "    classes = clf.classes_\n",
    "    imp = clf.coef_\n",
    "    result = []\n",
    "    for el, cls in enumerate(classes):\n",
    "        important_words = sorted(list(zip(words, imp[el])), key=lambda x: abs(x[1]), reverse=True)[len(imp) - top:]\n",
    "        result.append(set(important_words))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_data = common(count_vectorizer, clf, top=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_un = common_data[0] & common_data[1] & common_data[2]\n",
    "stop_words = []\n",
    "for word in data_un:\n",
    "    stop_words.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1745"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как это сработает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['normalized_new_stops'] = train_data['text'].apply(normalize)\n",
    "test_data['normalized_new_stops'] = test_data['text'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6806231742940604"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_4, X_test_4, count_vectorizer = Vecrotizer(train_data.normalized_new_stops,\n",
    "                                                 test_data.normalized_new_stops)\n",
    "clf, normalized_new_stops, y_pred_4 = logistic(X_train_4, y_train, X_test_4, y_test)\n",
    "normalized_new_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.73      0.67      0.70       902\n",
      "          0       0.68      0.76      0.71       972\n",
      "          1       0.43      0.33      0.37       180\n",
      "\n",
      "avg / total       0.68      0.68      0.68      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.5952340216744538\n",
      "Микросредняя F1 мера -  0.6806231742940604\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_4))\n",
    "print('Макросредняя F1 мера - ',f1_score(y_test, y_pred_4, average='macro'))\n",
    "print('Микросредняя F1 мера - ',f1_score(y_test, y_pred_4, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
