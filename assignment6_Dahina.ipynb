{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train-balanced-sarcasm.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "66f3572f754d29df76fa7de21fd2b359878ab296"
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.externals import joblib\nimport nltk\nimport gensim\nimport spacy\nfrom tqdm import tqdm_notebook\n\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\n\nimport torch as tt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torchtext.data import Field, LabelField, BucketIterator, ReversibleField, TabularDataset\n\n\n\nSEED = 42\nnp.random.seed(SEED)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "03e1f4dc30fa9fc1c3e7df84315ddcef6a137fcb"
      },
      "cell_type": "code",
      "source": "data = pd.read_csv('../input/train-balanced-sarcasm.csv')",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aaa5408b94fe31e34419c92a039d69c6ec120f15"
      },
      "cell_type": "code",
      "source": "data.label.value_counts()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "1    505413\n0    505413\nName: label, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3edcb4ac55e72da89db27a0a50e3c5b8ed47cbf9"
      },
      "cell_type": "code",
      "source": "data.head()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "   label                        ...                                                             parent_comment\n0      0                        ...                          Yeah, I get that argument. At this point, I'd ...\n1      0                        ...                          The blazers and Mavericks (The wests 5 and 6 s...\n2      0                        ...                                                    They're favored to win.\n3      0                        ...                                                 deadass don't kill my buzz\n4      0                        ...                          Yep can confirm I saw the tool they use for th...\n\n[5 rows x 10 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>comment</th>\n      <th>author</th>\n      <th>subreddit</th>\n      <th>score</th>\n      <th>ups</th>\n      <th>downs</th>\n      <th>date</th>\n      <th>created_utc</th>\n      <th>parent_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NC and NH.</td>\n      <td>Trumpbart</td>\n      <td>politics</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-16 23:55:23</td>\n      <td>Yeah, I get that argument. At this point, I'd ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>You do know west teams play against west teams...</td>\n      <td>Shbshb906</td>\n      <td>nba</td>\n      <td>-4</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-11</td>\n      <td>2016-11-01 00:24:10</td>\n      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>They were underdogs earlier today, but since G...</td>\n      <td>Creepeth</td>\n      <td>nfl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2016-09</td>\n      <td>2016-09-22 21:45:37</td>\n      <td>They're favored to win.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>This meme isn't funny none of the \"new york ni...</td>\n      <td>icebrotha</td>\n      <td>BlackPeopleTwitter</td>\n      <td>-8</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-18 21:03:47</td>\n      <td>deadass don't kill my buzz</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>I could use one of those tools.</td>\n      <td>cush2push</td>\n      <td>MaddenUltimateTeam</td>\n      <td>6</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-12</td>\n      <td>2016-12-30 17:00:13</td>\n      <td>Yep can confirm I saw the tool they use for th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ff91c91c019be08164e3e0e6ed293b70577b168a"
      },
      "cell_type": "code",
      "source": "import spacy\n\n\nspacy_en = spacy.load('en')\nspacy_en.remove_pipe('tagger')\nspacy_en.remove_pipe('ner')\n\ndef tokenizer(text): # create a tokenizer function\n    return [tok.lemma_ for tok in spacy_en.tokenizer(text)]",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "71137157c30a254965b38de03244514b84ddf66b"
      },
      "cell_type": "code",
      "source": "classes={\n    '0':0,\n    '1':1\n}\n\nTEXT = Field(include_lengths=True, batch_first=True, \n             tokenize=tokenizer,\n             eos_token='<eos>',\n             lower=True,\n             stop_words=nltk.corpus.stopwords.words('english')\n            )\nLABEL = LabelField(dtype=tt.int64, use_vocab=True, preprocessing=lambda x: classes[x])\n\ndataset = TabularDataset('../input/train-balanced-sarcasm.csv', format='csv', \n                         fields=[('label', LABEL), ('text', TEXT),(None, None),(None, None), \n                                 (None, None), (None, None), (None, None), (None, None), (None, None), \n                                 (None, None)],\n                         skip_header=True)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "TEXT.build_vocab(dataset, min_freq=5)\nlen(TEXT.vocab.itos)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "35493"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "617622ef43631c9072ebbdd9eecf243ca5816af8"
      },
      "cell_type": "code",
      "source": "TEXT.vocab.itos[:10]",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "['<unk>', '<pad>', '<eos>', '.', ',', '-pron-', '?', '!', '\"', '...']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "da7b2f589e2e3a9d2517f835214ace9c21b6b606"
      },
      "cell_type": "code",
      "source": "LABEL.build_vocab(dataset)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c39104df10cc5b622de56b915f0f7163383cf806"
      },
      "cell_type": "code",
      "source": "train, test = dataset.split(0.8, stratified=True)\ntrain, valid = train.split(0.9, stratified=True)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f4130a7e44791dc7aab141629daf63f765699c8"
      },
      "cell_type": "code",
      "source": "np.unique([x.label for x in train.examples], return_counts=True)",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "(array([0, 1]), array([363897, 363897]))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e462f66da91f27d6f6fb94bef4c5c4e311a9565f"
      },
      "cell_type": "code",
      "source": "np.unique([x.label for x in valid.examples], return_counts=True)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "(array([0, 1]), array([40433, 40433]))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "99a2f79906d5678fe45723878c1f90a784e84e8a"
      },
      "cell_type": "code",
      "source": "np.unique([x.label for x in test.examples], return_counts=True)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "(array([0, 1]), array([101083, 101083]))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c1c3d5b2d2cd529639f9ea9aed4d7fcf9a5030b2"
      },
      "cell_type": "code",
      "source": "class MyModel(nn.Module):\n    \n    def __init__(self, vocab_size, embed_size, hidden_size):\n        super(MyModel, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        \n        self.rnn = nn.LSTM(input_size=embed_size,\n                           hidden_size=hidden_size,\n                           bidirectional=True,\n                           batch_first=True,\n                          )\n        \n        self.fc = nn.Linear(hidden_size * 2 * 2, 2)\n        self.dropout = nn.Dropout(0.5)\n        \n    def forward(self, batch):\n        \n        x, x_lengths = batch.text\n        \n        x = self.embedding(x)\n\n        if x_lengths is not None:\n            x_lengths = x_lengths.view(-1).tolist()\n            x = nn.utils.rnn.pack_padded_sequence(x, x_lengths, batch_first=True)\n            \n        _, (hidden, cell) = self.rnn(x)\n        \n        #hidden = hidden.transpose(0,1)\n        cell = cell.transpose(0,1)\n        #hidden = hidden.contiguous().view(hidden.size(0),-1)        \n        hidden = self.dropout(tt.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))        \n        cell = cell.contiguous().view(cell.size(0),-1)\n        x = tt.cat([hidden, cell], dim=1).squeeze(1)\n        x = self.fc(x)\n        return x",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6c99d3a9321864e61aedee23b6d8199fc86ba1c9"
      },
      "cell_type": "code",
      "source": "tt.cuda.empty_cache()\n\nbatch_size = 32\n\nmodel = MyModel(len(TEXT.vocab.itos),\n                embed_size=100,\n                hidden_size=128,\n               )\n\n\n\ntrain_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n    (train, valid, test),\n    batch_sizes=(batch_size, batch_size, batch_size),\n    shuffle=True,\n    sort_key=lambda x: len(x.text),\n    sort_within_batch=True)\n\noptimizer = optim.Adam(model.parameters())\n# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True, cooldown=5)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\ncriterion = nn.CrossEntropyLoss()",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e6a5b8d56947979156d3b33eb25d2e39b2b6b7dc"
      },
      "cell_type": "code",
      "source": "def _train_epoch(model, iterator, optimizer, criterion, curr_epoch):\n\n    model.train()\n\n    running_loss = 0\n\n    n_batches = len(iterator)\n    iterator = tqdm_notebook(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n\n    for i, batch in enumerate(iterator):\n        optimizer.zero_grad()\n\n        pred = model(batch)\n        loss = criterion(pred, batch.label)\n        loss.backward()\n        optimizer.step()\n\n        curr_loss = loss.data.cpu().detach().item()\n        \n        loss_smoothing = i / (i+1)\n        running_loss = loss_smoothing * running_loss + (1 - loss_smoothing) * curr_loss\n\n        iterator.set_postfix(loss='%.5f' % running_loss)\n\n    return running_loss\n\ndef _test_epoch(model, iterator, criterion):\n    model.eval()\n    epoch_loss = 0\n\n    n_batches = len(iterator)\n    with tt.no_grad():\n        for batch in iterator:\n            pred = model(batch)\n            loss = criterion(pred, batch.label)\n            epoch_loss += loss.data.item()\n\n    return epoch_loss / n_batches\n\ndef _test_final(model, iterator, criterion):\n    model.eval()\n    epoch_loss = 0\n    acc_total = 0\n    n_batches = len(iterator)\n    \n    with tt.no_grad():\n        for batch in iterator:\n            y_pred = tt.nn.functional.softmax(model(batch), dim=1).detach().numpy().argmax(axis=1)\n            acc_score = metrics.accuracy_score(y_pred, batch.label)\n            acc_total += acc_score\n\n    return acc_total / n_batches\n\n\ndef nn_train(model, train_iterator, valid_iterator, criterion, optimizer, n_epochs=100,\n          scheduler=None, early_stopping=0):\n\n    prev_loss = 100500\n    es_epochs = 0\n    best_epoch = None\n    history = pd.DataFrame()\n\n    for epoch in range(n_epochs):\n        train_loss = _train_epoch(model, train_iterator, optimizer, criterion, epoch)\n        valid_loss = _test_epoch(model, valid_iterator, criterion)\n\n        valid_loss = valid_loss\n        print('validation loss %.5f' % valid_loss)\n\n        record = {'epoch': epoch, 'train_loss': train_loss, 'valid_loss': valid_loss}\n        history = history.append(record, ignore_index=True)\n\n        if early_stopping > 0:\n            if valid_loss > prev_loss:\n                es_epochs += 1\n            else:\n                es_epochs = 0\n\n            if es_epochs >= early_stopping:\n                best_epoch = history[history.valid_loss == history.valid_loss.min()].iloc[0]\n                print('Early stopping! best epoch: %d val %.5f' % (best_epoch['epoch'], best_epoch['valid_loss']))\n                break\n\n            prev_loss = min(prev_loss, valid_loss)",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dfd68bcce98e9d33bd94eb96fb0be7723fc4fa41"
      },
      "cell_type": "code",
      "source": "nn_train(model, train_iterator, valid_iterator, criterion, optimizer, scheduler=scheduler, \n        n_epochs=10, early_stopping=2)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, description='epoch 0', max=22744, style=ProgressStyle(description_width='i…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11325125e4b742ad91b7efbc2ccc6eb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\nvalidation loss 0.55824\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, description='epoch 1', max=22744, style=ProgressStyle(description_width='i…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4dac13fca8c34389bcd981b892da1a87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\nvalidation loss 0.55539\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, description='epoch 2', max=22744, style=ProgressStyle(description_width='i…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cdb019070b94485acfc811bcb9b4032"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\nvalidation loss 0.56382\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, description='epoch 3', max=22744, style=ProgressStyle(description_width='i…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e360988e795c4cc1a266da07393394f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\nvalidation loss 0.58383\nEarly stopping! best epoch: 1 val 0.55539\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "55519d429dd174c46c1c9452af6429fa939b3edf"
      },
      "cell_type": "code",
      "source": "count_test_accuracy(model, test_iterator)",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "0.7095082772166105"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "b7582f2739d41c4b1d42c91dfffa898782761b6a"
      },
      "cell_type": "markdown",
      "source": "Baseline 0.7 accuracy побит! Ура-ура!"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f77b39149fb01f9ae641f3e0f6f7e6edd2fd6cec"
      },
      "cell_type": "code",
      "source": "def count_test_accuracy(model, test_iterator):\n    \n    model.eval()\n    \n    epoch_acc, n_batches = 0, len(test_iterator)\n    \n    with tt.no_grad():\n        for batch in test_iterator:\n            \n            pred = model(batch)\n            \n            \n            pred = tt.softmax(pred, dim=-1)\n            pred = pred.detach().numpy()\n            \n            accuracy = accuracy_score(batch.label, pred.argmax(axis=1))\n            epoch_acc += accuracy.item()\n            \n        \n    return epoch_acc / n_batches",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a0b5dd748983ac946e58ba4db0895b8a66a0542a"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "65220a9e536cacfd31d74bcd42883da0d709630b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1edfb21cd3417c863690e522d1ed476e62de35ac"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}